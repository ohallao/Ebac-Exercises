{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Cite 5 diferenças entre o Random Forest e o AdaBoost\n",
        "\n",
        "\n",
        "*   No AdaBoost (AB), os modelos são treinados utilizando stumps, que são árvores de decisão rasas (geralmente com apenas um nível). No Random Forest (RF), são utilizadas árvores de decisão completas.\n",
        "\n",
        "*   No AB, os stumps são criados considerando todas as variáveis explicativas, mas o foco é dado nas amostras mal classificadas pelos modelos anteriores. No RF, uma quantidade máxima de variáveis é escolhida aleatoriamente em cada nó de uma árvore.\n",
        "\n",
        "*   No AB, o ajuste de pesos das amostras é feito a cada iteração, de modo que as observações mal classificadas recebem mais peso nas iterações subsequentes. No RF, o bootstrap (amostragem com reposição) dá o mesmo peso a todas as amostras.\n",
        "\n",
        "*   No AB, cada modelo treinado influencia o próximo, pois o treinamento é sequencial e depende do desempenho dos modelos anteriores. No RF, os modelos (árvores) são treinados de forma independente.\n",
        "\n",
        "*   No AB, os resultados das previsões dos modelos têm pesos diferentes no resultado final, com base no desempenho de cada modelo. No RF, todas as árvores contribuem igualmente para o resultado final, seja por votação majoritária (para classificação) ou por média (para regressão).\n"
      ],
      "metadata": {
        "id": "UEbk-AO96_8u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Acesse o link [Scikit-learn – adaboost](https://scikit-learn.org/stable/modules/ensemble.html), leia a explicação (traduza se for preciso) e crie um jupyter notebook contendo o exemplo do AdaBoost."
      ],
      "metadata": {
        "id": "sSBzeIHz7d1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "clf = AdaBoostClassifier(n_estimators=100, algorithm=\"SAMME\",)\n",
        "scores = cross_val_score(clf, X, y, cv=5)\n",
        "scores.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aLTT6z47fdh",
        "outputId": "63db57d9-33fe-48dd-ba29-6ed669df82f0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9533333333333334"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Cite 5 Hyperparametros importantes no AdaBoost.\n",
        "\n",
        "\n",
        "*   Modelo Base (base_estimator)\n",
        "*   Quantidade de Modelos (n_estimators)\n",
        "*   Taxa de Aprendizado (learning_rate)\n",
        "*   Algoritmo de Boosting (algorithm)\n",
        "*   early_stopping_rounds\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7Z4GHKJR8dIx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. (Opcional) Utilize o GridSearch para encontrar os melhores hyperparametros para o conjunto de dados do exemplo (load_iris)"
      ],
      "metadata": {
        "id": "rgGwUJ4K9W4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "params = {\n",
        "    \"n_estimators\": [10, 50, 100, 200, 500],\n",
        "    \"learning_rate\": [0.001, 0.01, 0.1, 1.0, 1.5, 2.0],\n",
        "}\n",
        "\n",
        "clf = AdaBoostClassifier()\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator = clf,\n",
        "    param_grid=params,\n",
        "    n_jobs=-1,\n",
        "    cv=2,\n",
        "    scoring='accuracy'\n",
        ")\n",
        "\n",
        "grid_result = grid_search.fit(X, y)\n",
        "grid_result.best_score_\n",
        "grid_result.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApSlybRo8erc",
        "outputId": "24daf2e6-8eb3-4746-eb97-74286150c4b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 714 ms, sys: 89.2 ms, total: 804 ms\n",
            "Wall time: 27.2 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.001, 'n_estimators': 200}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}